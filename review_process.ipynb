{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:37:15.519102Z",
     "start_time": "2024-12-03T05:37:15.157205Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fix_and_read_csv(file_path):\n",
    "    # Read the file content\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Take the first line as header\n",
    "        header = file.readline().strip()\n",
    "        content = file.read()\n",
    "    \n",
    "    # Fix the line breaks within fields\n",
    "    fixed_content = header + '\\n'\n",
    "    in_review = False\n",
    "    for line in content.split('\\n'):\n",
    "        if line.startswith(tuple('0123456789')) and ',' in line:\n",
    "            # This is a new entry\n",
    "            if len(fixed_content) > len(header) + 1:  # Exclude the first line\n",
    "                fixed_content += '\\n'\n",
    "            in_review = True\n",
    "            fixed_content += line\n",
    "        elif in_review:\n",
    "            # This is a continuation of the previous line\n",
    "            fixed_content += ' ' + line.strip()\n",
    "    \n",
    "    # Create DataFrame from fixed content\n",
    "    df = pd.read_csv(StringIO(fixed_content))\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T04:59:25.432762Z",
     "start_time": "2024-11-26T04:59:25.414632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def merge_reviews(file_list):\n",
    "    all_reviews = []\n",
    "    for file_path in tqdm(file_list):\n",
    "        # Extract car make from the file name\n",
    "        base_name = os.path.basename(file_path)\n",
    "        parts = base_name.split('_')\n",
    "        car_make = parts[-1].replace('.csv', '')\n",
    "        # Read and fix CSV\n",
    "        df = fix_and_read_csv(file_path)\n",
    "        \n",
    "        # Add the 'Car_Make' column\n",
    "        df['Car_Make'] = car_make\n",
    "        \n",
    "        # Append to list\n",
    "        all_reviews.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames into a single one\n",
    "    merged_df = pd.concat(all_reviews, ignore_index=True)\n",
    "    return merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T04:59:25.469983Z",
     "start_time": "2024-11-26T04:59:25.419375Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_Volkswagen.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_lamborghini.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_lotus.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_isuzu.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_ferrari.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_GMC.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_land-rover.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_lincoln.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_BMW.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_rolls-royce.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Review_Cadillac.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_mercury.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_mercedes-benz.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_AstonMartin.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_porsche.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_genesis.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_mazda.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_Honda.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_mini.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_Audi.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_maybach.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_AlfaRomeo.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_hyundai.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_Toyota.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_kia.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_maserati.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_subaru.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Review_Buick.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_fiat.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Review_Bugatti.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_AMGeneral.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_Acura.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_lexus.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_hummer.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_jeep.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_ford.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_pontiac.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_mitsubishi.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_nissan.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_jaguar.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_tesla.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_volvo.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_dodge.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_mclaren.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_infiniti.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Reviews_Bentley.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_ram.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Review_chrysler.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scraped_Car_Review_suzuki.csv', '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews/Scrapped_Car_Review_Chevrolet.csv']\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory\n",
    "directory = '/Users/kai/Documents/Study/S&DS625 Case/Carismatic/data/car_reviews'\n",
    "file_list = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "print(file_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T04:59:25.470962Z",
     "start_time": "2024-11-26T04:59:25.423920Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 21.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the files\n",
    "merged_df = merge_reviews(file_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T04:59:27.789271Z",
     "start_time": "2024-11-26T04:59:25.429066Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T05:26:28.958861Z",
     "start_time": "2024-11-26T05:26:28.890529Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop first column\n",
    "merged_df = merged_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "merged_df.to_csv('review_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T05:26:32.375023Z",
     "start_time": "2024-11-26T05:26:30.355158Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T05:44:35.292622Z",
     "start_time": "2024-11-26T05:44:35.277492Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- `df_a` is car dataset \n",
    "- `df_b` is review dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "df_a = pd.read_csv('data.csv')\n",
    "df_b = merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T05:44:35.486947Z",
     "start_time": "2024-11-26T05:44:35.462015Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract Maker, Model and Year from review dataset and fuzzy match with car dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227080/227080 [7:15:11<00:00,  8.70it/s]   \n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def find_match(row, df_a):\n",
    "    try:\n",
    "        # Create a string to match from df_a columns\n",
    "        df_a['full_name'] = df_a['Genmodel'] + ' ' + df_a['Year'].astype(str)\n",
    "        \n",
    "        # Extract components from Vehicle_Title\n",
    "        title_parts = row['Vehicle_Title'].split()\n",
    "        year = title_parts[0]\n",
    "        maker = title_parts[1]\n",
    "        model = ' '.join(title_parts[2:4])  # Usually brand and model\n",
    "    \n",
    "        # Calculate similarity scores\n",
    "        maker_scores = df_a['Maker'].apply(lambda x: fuzz.ratio(x.lower(), maker.lower()))\n",
    "        model_scores = df_a['Genmodel'].apply(lambda x: fuzz.ratio(x.lower(), model.lower()))\n",
    "        year_scores = df_a['Year'].apply(lambda x: fuzz.ratio(str(x).lower(), year.lower()))\n",
    "    \n",
    "        # Combine scores with different weights\n",
    "        total_scores = maker_scores * 0.45 + model_scores * 0.45 + year_scores * 0.1\n",
    "    \n",
    "        # Find the best match\n",
    "        best_score = max(total_scores)\n",
    "        best_match_idx = total_scores.idxmax()\n",
    "    \n",
    "        # Logging for evaluation\n",
    "        # print(best_score, maker, model, year, df_a.loc[best_match_idx, 'full_name'])\n",
    "    \n",
    "        # Return the index of the best match if it's a good match\n",
    "        return best_match_idx if best_score > 70 else None\n",
    "    except Exception as e:\n",
    "        # Log the error if needed and return None to signify a non-match\n",
    "        # print(f\"Skipping due to error: {e} for vehicle title: {row['Vehicle_Title']}\")\n",
    "        return None\n",
    "\n",
    "# Apply the modified matching function\n",
    "df_b['match_idx'] = df_b.progress_apply(lambda row: find_match(row, df_a), axis=1)\n",
    "\n",
    "# Filter out non-matches\n",
    "filtered_df_b = df_b[df_b['match_idx'].notna()]\n",
    "\n",
    "# Merge the dataframes\n",
    "result = filtered_df_b.merge(df_a, left_on='match_idx', right_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T12:59:47.630088Z",
     "start_time": "2024-11-26T05:44:35.761823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "data": {
      "text/plain": "   Year Genmodel_ID                                             Review  Rating\n0  2007        95_3   I've had my Beetle Convertible for over 4.5 y...   4.500\n1  2007        95_3   We bought the car new in 2007 and are general...   4.375\n2  2007        95_3   I adore my New Beetle. Even though I'm a male...   4.375\n3  2007        95_3   My wife chose this car to replace a Sebring c...   4.375\n4  2007        95_3   4 of us carpool 1 way 30 min.  Backseat ok fo...   4.750",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Genmodel_ID</th>\n      <th>Review</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007</td>\n      <td>95_3</td>\n      <td>I've had my Beetle Convertible for over 4.5 y...</td>\n      <td>4.500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007</td>\n      <td>95_3</td>\n      <td>We bought the car new in 2007 and are general...</td>\n      <td>4.375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007</td>\n      <td>95_3</td>\n      <td>I adore my New Beetle. Even though I'm a male...</td>\n      <td>4.375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007</td>\n      <td>95_3</td>\n      <td>My wife chose this car to replace a Sebring c...</td>\n      <td>4.375</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007</td>\n      <td>95_3</td>\n      <td>4 of us carpool 1 way 30 min.  Backseat ok fo...</td>\n      <td>4.750</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter Year, Genmodel_ID and Review and Rating\n",
    "result = result[['Year', 'Genmodel_ID', 'Review', 'Rating']]\n",
    "result.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T12:59:47.637126Z",
     "start_time": "2024-11-26T12:59:47.550848Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "# result.to_csv(\"final_data_raw.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T12:59:48.655755Z",
     "start_time": "2024-11-26T12:59:47.571949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"final_data_raw.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:37:21.501693Z",
     "start_time": "2024-12-03T05:37:20.598011Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "result = result[['Year', 'Genmodel_ID', 'Review', 'Rating']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:37:22.072191Z",
     "start_time": "2024-12-03T05:37:22.056512Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kai/miniconda3/envs/car/lib/python3.11/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/kai/miniconda3/envs/car/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <253997FD-685F-34A9-B3D7-4AF6DAE96CDF> /Users/kai/miniconda3/envs/car/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/kai/miniconda3/envs/car/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/kai/miniconda3/envs/car/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/kai/miniconda3/envs/car/lib/python3.11/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/kai/miniconda3/envs/car/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "pipe = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "# Initialize the tokenizer for your model to tokenize text\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")  # Replace with the actual model name\n",
    "max_length = tokenizer.model_max_length  # Typically 512 for BERT models\n",
    "\n",
    "print(max_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:37:26.228766Z",
     "start_time": "2024-12-03T05:37:22.864166Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 508/117630 [00:38<2:16:29, 14.30it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
      "  5%|▌         | 6313/117630 [08:09<2:17:19, 13.51it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (514) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 10776/117630 [13:20<2:08:23, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (513) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 26142/117630 [31:33<2:10:54, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (514) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 26701/117630 [32:13<1:43:38, 14.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (514) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 34902/117630 [41:59<1:37:38, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (513) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 38735/117630 [46:52<1:48:50, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (514) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 59338/117630 [1:12:03<1:01:16, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (513) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 65593/117630 [1:20:15<1:28:48,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (514) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 78605/117630 [1:35:57<47:04, 13.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (513) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 97430/117630 [1:58:26<21:28, 15.68it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (513) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 101054/117630 [2:02:47<23:07, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (514) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 102423/117630 [2:04:28<15:23, 16.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing review: The size of tensor a (513) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117630/117630 [2:22:04<00:00, 13.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Map from star labels to numerical values\n",
    "star_to_numeric = {\n",
    "    '1 star': 1,\n",
    "    '2 stars': 2,\n",
    "    '3 stars': 3,\n",
    "    '4 stars': 4,\n",
    "    '5 stars': 5\n",
    "}\n",
    "\n",
    "# Function to safely convert sentiment label to numeric\n",
    "def safe_convert(review):\n",
    "    # Check if the review is a string\n",
    "    if not isinstance(review, str):\n",
    "        return None  # Or some default/special value\n",
    "\n",
    "    # Tokenize and truncate the review if necessary\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    if len(tokens) > max_length:\n",
    "        review = tokenizer.convert_tokens_to_string(tokens[:max_length - 2])\n",
    "\n",
    "    try:\n",
    "        # Process the review and convert the label to numeric\n",
    "        sentiment_label = pipe(review)[0]['label']\n",
    "        return star_to_numeric.get(sentiment_label, None)  # None or some default for unknown labels\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review: {e}\")\n",
    "        return None  # Or handle the error as required\n",
    "\n",
    "# Apply the function to the reviews\n",
    "result['Sentiment Rating'] = result['Review'].progress_apply(safe_convert)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T07:59:58.171143Z",
     "start_time": "2024-12-03T05:37:53.425359Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "result.to_csv(\"final_data_2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T07:59:59.069658Z",
     "start_time": "2024-12-03T07:59:58.169784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Rename rating as review_rating\n",
    "result = result.rename(columns={'Rating': 'Review_Rating'})\n",
    "result = result[['Year', 'Genmodel_ID', 'Review_Rating', 'Sentiment Rating']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T14:50:44.255286Z",
     "start_time": "2024-12-03T14:50:44.241626Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "result.to_csv(\"processed_review_data.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T14:51:13.519939Z",
     "start_time": "2024-12-03T14:51:13.375874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
